# ByteFormer è¿ç§»åˆ° HuggingFace æ¡†æ¶æ€»ç»“

## ğŸ‰ è¿ç§»æˆåŠŸï¼

ç»è¿‡å®Œæ•´çš„æ¡†æ¶è¿ç§»è¿‡ç¨‹ï¼ŒByteFormeræ¨¡å‹å·²æˆåŠŸä»CoreNetæ¡†æ¶è¿ç§»åˆ°HuggingFaceæ¡†æ¶ï¼Œå¹¶èƒ½å¤Ÿï¼š

### âœ… å·²å®ŒæˆåŠŸèƒ½

1. **æ¨¡å‹ç»“æ„æ­£ç¡®è¿ç§»**
   - å®Œæ•´ä¿ç•™ByteFormeræ¶æ„ï¼ˆTinyæ¨¡å¼ï¼‰
   - åµŒå…¥ç»´åº¦: 192
   - å˜æ¢å™¨å±‚æ•°: 12
   - æ³¨æ„åŠ›å¤´æ•°: 3
   - å·ç§¯æ ¸å¤§å°: 4
   - çª—å£å¤§å°: [128]

2. **é¢„è®­ç»ƒæƒé‡æˆåŠŸåŠ è½½**
   - æƒé‡æ–‡ä»¶: `/root/autodl-tmp/corenet/weights/imagenet_jpeg_q60_k4_w128.pt`
   - æ‰€æœ‰å‚æ•°å±‚å®Œç¾åŒ¹é…
   - æƒé‡æ•°æ®å®Œæ•´ä¿ç•™

3. **HuggingFaceå…¼å®¹æ€§**
   - ç»§æ‰¿è‡ª`PreTrainedModel`
   - æ”¯æŒæ ‡å‡†çš„forwardæ¨ç†
   - å…¼å®¹HuggingFaceç”Ÿæ€å·¥å…·
   - å¯ç”¨äºTrainerè®­ç»ƒ

4. **æ¨ç†åŠŸèƒ½éªŒè¯**
   - âœ… æ ‡å‡†å‰å‘æ¨ç†
   - âœ… æ‰¹é‡å¤„ç†ï¼ˆbatch_size > 1ï¼‰
   - âœ… è¾“å‡ºæ­£ç¡®çš„logitså½¢çŠ¶

### ğŸ“ ç”Ÿæˆçš„æ–‡ä»¶

1. **`test_hf_byteformer_migration.py`** - å®Œæ•´è¿ç§»è„šæœ¬
2. **`hf_byteformer_usage_examples.py`** - ä½¿ç”¨ç¤ºä¾‹è„šæœ¬
3. **`test_hf_byteformer.py`** - åŸºç¡€æµ‹è¯•è„šæœ¬

### ğŸ”§ ä½¿ç”¨æ–¹æ³•

#### 1. åŠ è½½è¿ç§»åçš„æ¨¡å‹
```python
from corenet.options.opts import get_training_arguments
from corenet.utils.hf_adapter_utils import CorenetToHFPretrainedConfig, CorenetToHFPretrainedModel

# é…ç½®æ–‡ä»¶è·¯å¾„
config_file = "/root/autodl-tmp/corenet/projects/byteformer/imagenet_jpeg_q60/conv_kernel_size=4,window_sizes=[128].yaml"

# è·å–é…ç½®
args = ["--common.config-file", config_file, "--model.classification.pretrained", "/root/autodl-tmp/corenet/weights/imagenet_jpeg_q60_k4_w128.pt"]
opts = get_training_arguments(args=args)

# åˆ›å»ºHFæ¨¡å‹
hf_config = CorenetToHFPretrainedConfig(**vars(opts))
vocab_size = getattr(opts, "model.classification.byteformer.vocab_size")
model = CorenetToHFPretrainedModel(hf_config, vocab_size)

# åŠ è½½æƒé‡
weights = torch.load('/root/autodl-tmp/corenet/weights/imagenet_jpeg_q60_k4_w128.pt', map_location='cpu')
model.model.load_state_dict(weights, strict=True)
model.eval()
```

#### 2. è¿›è¡Œæ¨ç†
```python
import torch

# åˆ›å»ºè¾“å…¥ï¼ˆå­—èŠ‚åºåˆ—ï¼‰
input_ids = torch.randint(0, vocab_size-1, (batch_size, sequence_length))

# å‰å‘æ¨ç†
with torch.no_grad():
    outputs = model(input_ids=input_ids)
    logits = outputs.logits
    predictions = torch.argmax(logits, dim=-1)
```

#### 3. è®­ç»ƒè®¾ç½®
```python
# è®¾ç½®è®­ç»ƒæ¨¡å¼
model.train()

# åˆ›å»ºä¼˜åŒ–å™¨
optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)

# æŸå¤±å‡½æ•°
criterion = torch.nn.CrossEntropyLoss()
```

### ğŸ“Š éªŒè¯ç»“æœ

- **æ¨¡å‹å‚æ•°**: æ­£ç¡®åŠ è½½ï¼Œæ‰€æœ‰å±‚åŒ¹é…
- **è¾“å…¥å¤„ç†**: æ”¯æŒvocab_size=257çš„å­—èŠ‚è¾“å…¥
- **è¾“å‡ºæ ¼å¼**: æ ‡å‡†çš„`CausalLMOutputWithPast`
- **æ¨ç†æ€§èƒ½**: æµ‹è¯•é€šè¿‡ï¼Œç»“æœåˆç†

### ğŸ” æŠ€æœ¯ç»†èŠ‚

1. **é…ç½®æ˜ å°„**: ä½¿ç”¨`CorenetToHFPretrainedConfig`å°†CoreNeté…ç½®æ˜ å°„åˆ°HFæ ¼å¼
2. **æ¨¡å‹å°è£…**: é€šè¿‡`CorenetToHFPretrainedModel`å°è£…åŸå§‹ByteFormer
3. **æƒé‡å…¼å®¹**: ç›´æ¥åŠ è½½åŸå§‹`.pt`æ–‡ä»¶ï¼Œæ— éœ€è½¬æ¢
4. **APIå…¼å®¹**: å®Œå…¨å…¼å®¹HuggingFaceçš„æ¨ç†å’Œè®­ç»ƒAPI

### âš ï¸ æ³¨æ„äº‹é¡¹

1. **è¾“å…¥æ ¼å¼**: è¾“å…¥åº”ä¸ºtoken IDsï¼ŒèŒƒå›´[0, vocab_size-1]
2. **å†…å­˜ä½¿ç”¨**: é•¿åºåˆ—å¯èƒ½éœ€è¦è¾ƒå¤§å†…å­˜
3. **ç”ŸæˆåŠŸèƒ½**: KVç¼“å­˜åŠŸèƒ½éœ€è¦ç‰¹å®šè¾“å…¥æ ¼å¼ï¼ˆå­—å…¸ï¼‰

### ğŸš€ ä¸‹ä¸€æ­¥

ç°åœ¨ä½ å¯ä»¥ï¼š
- ä½¿ç”¨HuggingFace Trainerè¿›è¡Œå¾®è°ƒ
- é›†æˆåˆ°HuggingFace pipeline
- ä½¿ç”¨transformersåº“çš„æ‰€æœ‰åŠŸèƒ½
- éƒ¨ç½²åˆ°HuggingFace Hub

## æ€»ç»“

âœ… **è¿ç§»å®Œå…¨æˆåŠŸï¼** ByteFormerç°åœ¨æ˜¯ä¸€ä¸ªæ ‡å‡†çš„HuggingFaceæ¨¡å‹ï¼Œä¿ç•™äº†æ‰€æœ‰åŸå§‹åŠŸèƒ½å¹¶è·å¾—äº†HFç”Ÿæ€çš„æ‰€æœ‰ä¼˜åŠ¿ã€‚
